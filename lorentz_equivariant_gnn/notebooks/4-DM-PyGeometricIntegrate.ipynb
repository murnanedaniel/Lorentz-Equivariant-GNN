{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98815d97",
   "metadata": {},
   "source": [
    "# Integrate with Pytorch Geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faeefbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa002468-50bd-46a5-b467-ed862e1547f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c96ece61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures.EquivariantGNN.Models.legnn import LEGNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255ebfa0",
   "metadata": {},
   "source": [
    "# Roadmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99c7cbe",
   "metadata": {},
   "source": [
    "- [X] Pull in toy quickstart\n",
    "- [X] Test batch 1 of toy\n",
    "- [X] Test batch N of toy\n",
    "- [ ] Tweak edge conv to fit LEGNN conv\n",
    "- [ ] Tweak forward to fit LEGNN and ParticleNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d325100",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## PyG Toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "613fb230",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='.', name='Cora')\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GCN(dataset.num_features, 16, dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "847aa27b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a4af480",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random_graphs = []\n",
    "for i in range(100):\n",
    "    x = torch.rand((100,3))\n",
    "    num_edges = torch.randint(1000, (1,))\n",
    "    edges = torch.randint(len(x), (2, num_edges))\n",
    "    y = torch.round(torch.rand(num_edges))\n",
    "    random_graphs.append(Data(x=x, edge_index = edges, y=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d6c564f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(random_graphs, shuffle=False, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6a17a39",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 88,   3,  57,  ..., 137, 193, 168],\n",
      "        [ 49,  81,  85,  ..., 105, 110, 124]])\n"
     ]
    }
   ],
   "source": [
    "for graph in dataloader:\n",
    "    \n",
    "    print(graph.edge_index)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1f5bd8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Test custom message passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1e36f61",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MessagePassing\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c624a90b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class EdgeConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='max') #  \"Max\" aggregation.\n",
    "        self.mlp = Seq(Linear(2 * in_channels, out_channels),\n",
    "                       ReLU(),\n",
    "                       Linear(out_channels, out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        print(\"Propagating\")\n",
    "        return self.propagate(edge_index, x=x)\n",
    "\n",
    "    def message(self, x_i, x_j):\n",
    "        # x_i has shape [E, in_channels]\n",
    "        # x_j has shape [E, in_channels]\n",
    "\n",
    "        print(\"Calculating message\")\n",
    "        tmp = torch.cat([x_i, x_j - x_i], dim=1)  # tmp has shape [E, 2 * in_channels]\n",
    "        return self.mlp(tmp)\n",
    "    \n",
    "    def update(self, aggr_out):\n",
    "        \n",
    "        print(\"Aggregating\")\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72626d50",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class VanillaGNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = EdgeConv(in_channels, hidden_channels)\n",
    "        self.conv2 = EdgeConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = VanillaGNN(3, 16, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "565dc30e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Propagating\n",
      "Calculating message\n",
      "Aggregating\n",
      "Propagating\n",
      "Calculating message\n",
      "Aggregating\n"
     ]
    }
   ],
   "source": [
    "for graph in dataloader:\n",
    "    output = model(graph.x, graph.edge_index)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ec6cdf76",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 7])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f57563",
   "metadata": {},
   "source": [
    "## LEGNN into PyG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec905b9f",
   "metadata": {},
   "source": [
    "- [ ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "808c4054",
   "metadata": {
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "import torch.nn as nn\n",
    "\n",
    "class L_GCL(MessagePassing):\n",
    "    def __init__(self, input_feature_dim, message_dim, output_feature_dim, edge_feature_dim, activation = nn.SiLU()):\n",
    "        super().__init__(aggr='add') #  \"Max\" aggregation.\n",
    "        \n",
    "        radial_dim = 1  # Only one number is needed to specify Minkowski distance\n",
    "        coordinate_dim = 4\n",
    "        self.message_dim = message_dim\n",
    "\n",
    "        # The MLP used to calculate messages\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(2 * input_feature_dim + radial_dim + edge_feature_dim, message_dim),\n",
    "            activation,\n",
    "            nn.Linear(message_dim, message_dim),\n",
    "            nn.Softsign()\n",
    "            #activation\n",
    "        )\n",
    "\n",
    "        # The MLP used to update the feature vectors h_i\n",
    "        self.feature_mlp = nn.Sequential(\n",
    "            nn.Linear(input_feature_dim + message_dim, message_dim),\n",
    "            activation,\n",
    "            nn.Linear(message_dim, output_feature_dim),\n",
    "            nn.Softsign()\n",
    "        )\n",
    "\n",
    "        # Setup randomized weights\n",
    "        self.layer = nn.Linear(message_dim, 1, bias = False)\n",
    "        torch.nn.init.xavier_uniform_(self.layer.weight, gain = 0.001)\n",
    "\n",
    "        # The MLP used to update coordinates (node embeddings) x_i\n",
    "        self.coordinate_mlp = nn.Sequential(\n",
    "            nn.Linear(message_dim, message_dim),\n",
    "            activation,\n",
    "            self.layer\n",
    "        )\n",
    "\n",
    "        self.coordinate_linear_combination_mlp = nn.Linear(2 * coordinate_dim, coordinate_dim, bias = False)\n",
    "\n",
    "    def forward(self, x, h, edge_index, edge_attribute = None):\n",
    "        \n",
    "        radial, _ = self.compute_radials(edge_index, x)\n",
    "\n",
    "        return self.propagate(edge_index, x=x, h=h, radial=radial)\n",
    "\n",
    "    def message(self, x_i, x_j, h_i, h_j, radial):\n",
    "\n",
    "        \n",
    "        h_messages = self.compute_messages(h_i, h_j, radial)\n",
    "        x_messages = (x_i - x_j)*self.coordinate_mlp(h_messages)\n",
    "        \n",
    "        return torch.cat([h_messages, x_messages], axis=1)\n",
    "    \n",
    "    def update(self, aggr, x, h):\n",
    "        h_next = self.feature_mlp(torch.cat([aggr[:, :self.message_dim], h], axis=1) )\n",
    "        x_next = x + aggr[:, self.message_dim:]\n",
    "    \n",
    "        return h_next, x_next\n",
    "    \n",
    "    \n",
    "    def compute_messages(self, source, target, radial, edge_attribute = None):\n",
    "        \"\"\"\n",
    "        Calculates the messages to send between two nodes 'target' and 'source' to be passed through the network.\n",
    "        The message is computed via an MLP of Lorentz invariants.\n",
    "\n",
    "        :param source: The source node's feature vector h_i\n",
    "        :param target: The target node's feature vector h_j\n",
    "        :param radial: The Minkowski distance between the source and target's coordinates\n",
    "        :param edge_attribute: Features at the edge connecting the source and target nodes\n",
    "        :return: The message m_{ij}\n",
    "        \"\"\"\n",
    "        \n",
    "        if edge_attribute is None:\n",
    "            message_inputs = torch.cat([source, target, radial], dim = 1)  # Setup input for computing messages through MLP\n",
    "        else:\n",
    "            message_inputs = torch.cat([source, target, radial, edge_attribute], dim = 1)  # Setup input for computing messages through MLP\n",
    "\n",
    "        out = self.edge_mlp(message_inputs)  # Apply \\phi_e to calculate the messages\n",
    "        return out\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_radials(edge_index, x):\n",
    "        \"\"\"\n",
    "        Calculates the Minkowski distance (squared) between coordinates (node embeddings) x_i and x_j\n",
    "\n",
    "        :param edge_index: Array containing the connection between nodes\n",
    "        :param x: The coordinates (node embeddings)\n",
    "        :return: Minkowski distances (squared) and coordinate differences x_i - x_j\n",
    "        \"\"\"\n",
    "\n",
    "        row, col = edge_index\n",
    "        coordinate_differences = x[row] - x[col]\n",
    "        minkowski_distance_squared = coordinate_differences ** 2\n",
    "        minkowski_distance_squared[:, 0] = -minkowski_distance_squared[:, 0]  # Place minus sign on time coordinate as \\eta = diag(-1, 1, 1, 1)\n",
    "        radial = torch.sum(minkowski_distance_squared, 1).unsqueeze(1)\n",
    "        return radial, coordinate_differences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b989155f",
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "from architectures.EquivariantGNN.egnn_base import EGNNBase\n",
    "from torch import nn\n",
    "\n",
    "class LEGNN(EGNNBase):\n",
    "    \"\"\"\n",
    "    The main network used for Lorentz group equivariance consisting of several layers of L_GCLs\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hparams):\n",
    "#     input_feature_dim, message_dim, output_feature_dim, edge_feature_dim,\n",
    "#                  device = 'cpu', activation = nn.SiLU(), n_layers = 4):\n",
    "        \"\"\"\n",
    "        Sets up the equivariant network and creates the necessary L_GCL layers\n",
    "\n",
    "        :param input_feature_dim: The amount of numbers needed to specify a feature inputted into the LEGNN\n",
    "        :param message_dim: The amount of numbers needed to specify a message passed through the LEGNN\n",
    "        :param output_feature_dim: The amount of numbers needed to specify the updated feature after passing through the LEGNN\n",
    "        :param edge_feature_dim: The amount of numbers needed to specify an edge attribute a_{ij}\n",
    "        :param device: Specification on whether the cpu or gpu is to be used\n",
    "        :param activation: The activation function used as the main non-linearity throughout the LEGNN\n",
    "        :param n_layers: The number of layers the LEGNN network has\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(hparams)\n",
    "        self.message_dim = hparams[\"message_dim\"]\n",
    "        self.activation = getattr(nn, hparams[\"activation\"])\n",
    "        self.n_layers = hparams[\"n_layers\"]\n",
    "        self.feature_in = nn.Linear(hparams[\"input_feature_dim\"], self.message_dim)  # Initial mixing of features\n",
    "        self.feature_out = nn.Linear(self.message_dim, hparams[\"output_feature_dim\"])  # Final mixing of features to yield desired output\n",
    "\n",
    "        for i in range(0, hparams[\"n_layers\"]):\n",
    "            self.add_module(\"gcl_%d\" % i, L_GCL(self.message_dim, self.message_dim, self.message_dim,\n",
    "                                                hparams[\"edge_feature_dim\"], activation = self.activation()))\n",
    "\n",
    "    def forward(self, x, edges, edge_attribute = None):\n",
    "        \n",
    "        h = self.compute_initial_feature(edges, x)\n",
    "        h = self.feature_in(h.unsqueeze(1))\n",
    "        for i in range(0, self.n_layers):\n",
    "            h, x = self._modules[\"gcl_%d\" % i](x, h, edges, edge_attribute = edge_attribute)\n",
    "        h = self.feature_out(h)\n",
    "        return h, x\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_initial_feature(edge_index, x):\n",
    "        \"\"\"\n",
    "        Calculates the Minkowski distance (squared) between coordinates (node embeddings) x_i and x_j\n",
    "\n",
    "        :param edge_index: Array containing the connection between nodes\n",
    "        :param x: The coordinates (node embeddings)\n",
    "        :return: Minkowski distances (squared) and coordinate differences x_i - x_j\n",
    "        \"\"\"\n",
    "\n",
    "        momentum_squared = x**2\n",
    "        momentum_squared[:, 0] = -momentum_squared[:, 0]\n",
    "        minkowski_magnitude = torch.sum(momentum_squared, 1)\n",
    "        \n",
    "        return minkowski_magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0b63da",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4879f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/lgnn_config.yaml\") as f:\n",
    "        hparams = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e32d6a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LEGNN(hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865757ab",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbc78d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmurnanedaniel\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.9<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">vague-eon-68</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/murnanedaniel/LorentzNet\" target=\"_blank\">https://wandb.ai/murnanedaniel/LorentzNet</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/murnanedaniel/LorentzNet/runs/qus0vj56\" target=\"_blank\">https://wandb.ai/murnanedaniel/LorentzNet/runs/qus0vj56</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20210908_133251-qus0vj56</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name        | Type   | Params\n",
      "---------------------------------------\n",
      "0 | feature_in  | Linear | 256   \n",
      "1 | feature_out | Linear | 129   \n",
      "2 | gcl_0       | L_GCL  | 115 K \n",
      "3 | gcl_1       | L_GCL  | 115 K \n",
      "4 | gcl_2       | L_GCL  | 115 K \n",
      "5 | gcl_3       | L_GCL  | 115 K \n",
      "---------------------------------------\n",
      "462 K     Trainable params\n",
      "0         Non-trainable params\n",
      "462 K     Total params\n",
      "1.851     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:103: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f'The dataloader, {name}, does not have many workers which may be a bottleneck.'\n",
      "/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:103: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f'The dataloader, {name}, does not have many workers which may be a bottleneck.'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "045ac9185a5a468e9fae9f53e41ed333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: LightningDeprecationWarning: Relying on `self.log('val_loss', ...)` to set the ModelCheckpoint monitor is deprecated in v1.2 and will be removed in v1.4. Please, create your own `mc = ModelCheckpoint(monitor='your_monitor')` and use it as `Trainer(callbacks=[mc])`.\n",
      "  \"Relying on `self.log('val_loss', ...)` to set the ModelCheckpoint monitor is deprecated in v1.2\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger = WandbLogger(project=\"LorentzNet\", group=\"InitialTest\")\n",
    "trainer = Trainer(gpus=1, max_epochs=30, logger=logger)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670e0cad",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f699a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9daea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998f3aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a78b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240703f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfac1544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513cf352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510d3699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb3b84c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0329ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce2e696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c36633d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb410a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c8be6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b991359b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276bf139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2625cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698f5a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2188aa82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebff2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8a67cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2abfce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770572dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de2d360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ExatrkxTest",
   "language": "python",
   "name": "exatrkx-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
